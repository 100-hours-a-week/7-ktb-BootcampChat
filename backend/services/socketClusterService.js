const { createAdapter } = require('@socket.io/redis-adapter');
const { createClient } = require('redis');
const cluster = require('cluster');
const os = require('os');

class SocketClusterService {
  constructor() {
    this.redisClients = null;
    this.adapter = null;
    this.numCPUs = os.cpus().length;
  }

  // Redis Adapter ì„¤ì • (ë‹¤ì¤‘ ì„œë²„ ê°„ Socket.IO í†µì‹ )
  async setupRedisAdapter(io) {
    try {
      // Redis í´ë¼ì´ì–¸íŠ¸ 2ê°œ ìƒì„± (pub/subìš©)
      const pubClient = createClient({
        host: process.env.REDIS_HOST || 'localhost',
        port: process.env.REDIS_PORT || 6379,
        retry_strategy: (options) => {
          if (options.error && options.error.code === 'ECONNREFUSED') {
            return new Error('Redis server refused connection');
          }
          if (options.total_retry_time > 1000 * 60 * 60) {
            return new Error('Retry time exhausted');
          }
          if (options.attempt > 10) {
            return undefined;
          }
          return Math.min(options.attempt * 100, 3000);
        }
      });

      const subClient = pubClient.duplicate();

      await Promise.all([
        pubClient.connect(),
        subClient.connect()
      ]);

      // Redis Adapter ìƒì„±
      this.adapter = createAdapter(pubClient, subClient);
      io.adapter(this.adapter);

      this.redisClients = { pubClient, subClient };

      console.log('âœ… Socket.IO Redis Adapter connected');
      return true;
    } catch (error) {
      console.error('âŒ Failed to setup Redis Adapter:', error);
      return false;
    }
  }

  // í´ëŸ¬ìŠ¤í„° ëª¨ë“œ ì‹œì‘
  startCluster() {
    if (cluster.isMaster) {
      console.log(`ğŸš€ Master process ${process.pid} is running`);
      console.log(`ğŸ”¥ Starting ${this.numCPUs} worker processes...`);

      // CPU ì½”ì–´ ìˆ˜ë§Œí¼ ì›Œì»¤ ìƒì„±
      for (let i = 0; i < this.numCPUs; i++) {
        cluster.fork();
      }

      // ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ëª¨ë‹ˆí„°ë§
      cluster.on('exit', (worker, code, signal) => {
        console.log(`ğŸ’€ Worker ${worker.process.pid} died. Restarting...`);
        cluster.fork(); // ìë™ ì¬ì‹œì‘
      });

      // ì›Œì»¤ ìƒíƒœ ëª¨ë‹ˆí„°ë§
      setInterval(() => {
        const workers = Object.keys(cluster.workers).length;
        console.log(`ğŸ“Š Active workers: ${workers}/${this.numCPUs}`);
      }, 30000); // 30ì´ˆë§ˆë‹¤ ì²´í¬

    } else {
      // ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì„œë²„ ì‹œì‘
      console.log(`ğŸ‘· Worker ${process.pid} started`);
      return true; // ì›Œì»¤ì—ì„œ ì„œë²„ ì‹œì‘ ì‹ í˜¸
    }
    return false;
  }

  // ë¶€í•˜ ë¶„ì‚°ì„ ìœ„í•œ ë°© ë¶„ì‚° ë¡œì§
  getOptimalRoom(userId, availableRooms) {
    // ì‚¬ìš©ì ID í•´ì‹œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°© ë¶„ì‚°
    const hash = this.hashUserId(userId);
    const roomIndex = hash % availableRooms.length;
    return availableRooms[roomIndex];
  }

  // ì‚¬ìš©ì ID í•´ì‹œ í•¨ìˆ˜
  hashUserId(userId) {
    let hash = 0;
    for (let i = 0; i < userId.length; i++) {
      const char = userId.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // 32bit ì •ìˆ˜ë¡œ ë³€í™˜
    }
    return Math.abs(hash);
  }

  // Socket.IO ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¶„ì‚°
  createNamespaces(io) {
    const namespaces = {
      chat: io.of('/chat'),
      files: io.of('/files'),
      notifications: io.of('/notifications')
    };

    // ê° ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ ì—°ê²° ì œí•œ
    Object.entries(namespaces).forEach(([name, namespace]) => {
      namespace.use((socket, next) => {
        const connections = namespace.sockets.size;
        const limit = this.getNamespaceLimit(name);
        
        if (connections >= limit) {
          console.warn(`ğŸš¨ Namespace ${name} connection limit reached: ${connections}/${limit}`);
          return next(new Error(`Namespace ${name} is full`));
        }
        
        next();
      });
    });

    return namespaces;
  }

  // ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ ì—°ê²° ì œí•œ
  getNamespaceLimit(namespace) {
    const limits = {
      chat: 300,      // ì±„íŒ… ì „ìš©
      files: 100,     // íŒŒì¼ ì—…ë¡œë“œ ì „ìš©
      notifications: 500  // ì•Œë¦¼ ì „ìš©
    };
    return limits[namespace] || 100;
  }

  // ë©”ì‹œì§€ ë¸Œë¡œë“œìºìŠ¤íŒ… ìµœì í™”
  async optimizedBroadcast(io, roomId, event, data) {
    try {
      // ë°©ì— ìˆëŠ” ì‹¤ì œ ì‚¬ìš©ì ìˆ˜ í™•ì¸
      const sockets = await io.in(roomId).fetchSockets();
      
      if (sockets.length === 0) {
        console.log(`ğŸ“­ No users in room ${roomId}, skipping broadcast`);
        return;
      }

      // ëŒ€ìš©ëŸ‰ ë°ì´í„°ëŠ” ì••ì¶•í•´ì„œ ì „ì†¡
      if (JSON.stringify(data).length > 1024) { // 1KB ì´ìƒ
        data = await this.compressData(data);
      }

      // ë°°ì¹˜ ë¸Œë¡œë“œìºìŠ¤íŒ… (í•œ ë²ˆì— ìµœëŒ€ 50ëª…ì”©)
      const batchSize = 50;
      for (let i = 0; i < sockets.length; i += batchSize) {
        const batch = sockets.slice(i, i + batchSize);
        
        await Promise.all(
          batch.map(socket => 
            socket.emit(event, data).catch(err => 
              console.error(`Failed to emit to ${socket.id}:`, err)
            )
          )
        );
        
        // ë°°ì¹˜ ê°„ ì§§ì€ ì§€ì—° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
        if (i + batchSize < sockets.length) {
          await new Promise(resolve => setTimeout(resolve, 10));
        }
      }

      console.log(`ğŸ“¡ Broadcasted ${event} to ${sockets.length} users in room ${roomId}`);
    } catch (error) {
      console.error('Broadcast error:', error);
    }
  }

  // ë°ì´í„° ì••ì¶•
  async compressData(data) {
    const zlib = require('zlib');
    const compressed = zlib.gzipSync(JSON.stringify(data));
    return {
      compressed: true,
      data: compressed.toString('base64')
    };
  }

  // ì—°ê²° í’€ ê´€ë¦¬
  manageConnectionPool(io) {
    const connectionPool = {
      active: new Map(),
      idle: new Set(),
      maxConnections: 1000,
      idleTimeout: 5 * 60 * 1000 // 5ë¶„
    };

    // ì—°ê²° ì¶”ê°€
    io.on('connection', (socket) => {
      connectionPool.active.set(socket.id, {
        socket,
        lastActivity: Date.now(),
        userId: socket.user?.id
      });

      // ë¹„í™œì„± ì—°ê²° ê°ì§€
      socket.on('disconnect', () => {
        connectionPool.active.delete(socket.id);
        connectionPool.idle.delete(socket.id);
      });

      // í™œë™ ì—…ë°ì´íŠ¸
      socket.onAny(() => {
        const conn = connectionPool.active.get(socket.id);
        if (conn) {
          conn.lastActivity = Date.now();
        }
      });
    });

    // ë¹„í™œì„± ì—°ê²° ì •ë¦¬ (1ë¶„ë§ˆë‹¤)
    setInterval(() => {
      const now = Date.now();
      const toRemove = [];

      for (const [socketId, conn] of connectionPool.active) {
        if (now - conn.lastActivity > connectionPool.idleTimeout) {
          toRemove.push(socketId);
        }
      }

      toRemove.forEach(socketId => {
        const conn = connectionPool.active.get(socketId);
        if (conn) {
          console.log(`ğŸ§¹ Cleaning idle connection: ${socketId}`);
          conn.socket.disconnect(true);
          connectionPool.active.delete(socketId);
        }
      });

      console.log(`ğŸ“Š Connection Pool - Active: ${connectionPool.active.size}, Cleaned: ${toRemove.length}`);
    }, 60000);

    return connectionPool;
  }

  // ë©”ëª¨ë¦¬ ê¸°ë°˜ ë©”ì‹œì§€ í (Redis ë³´ì™„)
  createMessageQueue() {
    const messageQueue = {
      queues: new Map(),
      processing: new Set(),
      maxQueueSize: 1000,
      batchSize: 10
    };

    // ë©”ì‹œì§€ íì— ì¶”ê°€
    messageQueue.enqueue = (roomId, message) => {
      if (!messageQueue.queues.has(roomId)) {
        messageQueue.queues.set(roomId, []);
      }

      const queue = messageQueue.queues.get(roomId);
      if (queue.length >= messageQueue.maxQueueSize) {
        queue.shift(); // ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±°
      }

      queue.push({
        ...message,
        timestamp: Date.now(),
        id: `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`
      });
    };

    // ë°°ì¹˜ ì²˜ë¦¬
    messageQueue.processBatch = async (roomId) => {
      if (messageQueue.processing.has(roomId)) return;

      messageQueue.processing.add(roomId);
      const queue = messageQueue.queues.get(roomId) || [];
      
      if (queue.length === 0) {
        messageQueue.processing.delete(roomId);
        return;
      }

      const batch = queue.splice(0, messageQueue.batchSize);
      
      try {
        // ë°ì´í„°ë² ì´ìŠ¤ì— ë°°ì¹˜ ì €ì¥
        await this.saveBatchMessages(batch);
        console.log(`ğŸ’¾ Saved batch of ${batch.length} messages for room ${roomId}`);
      } catch (error) {
        console.error('Batch save error:', error);
        // ì‹¤íŒ¨í•œ ë©”ì‹œì§€ë“¤ì„ í ì•ìª½ì— ë‹¤ì‹œ ì¶”ê°€
        queue.unshift(...batch);
      } finally {
        messageQueue.processing.delete(roomId);
      }
    };

    // ì£¼ê¸°ì  ë°°ì¹˜ ì²˜ë¦¬ (5ì´ˆë§ˆë‹¤)
    setInterval(() => {
      for (const roomId of messageQueue.queues.keys()) {
        messageQueue.processBatch(roomId);
      }
    }, 5000);

    return messageQueue;
  }

  // ë°°ì¹˜ ë©”ì‹œì§€ ì €ì¥
  async saveBatchMessages(messages) {
    const Message = require('../models/Message');
    
    try {
      await Message.insertMany(messages, { ordered: false });
    } catch (error) {
      console.error('Batch message save error:', error);
      throw error;
    }
  }

  // ì„œë²„ ìƒíƒœ ëª¨ë‹ˆí„°ë§
  monitorServerHealth(io) {
    const healthMetrics = {
      connections: 0,
      memoryUsage: 0,
      cpuUsage: 0,
      lastCheck: Date.now()
    };

    setInterval(() => {
      const memUsage = process.memoryUsage();
      healthMetrics.connections = io.engine.clientsCount;
      healthMetrics.memoryUsage = memUsage.heapUsed / memUsage.heapTotal;
      healthMetrics.lastCheck = Date.now();

      // ì„ê³„ì¹˜ ì´ˆê³¼ ì‹œ ê²½ê³ 
      if (healthMetrics.memoryUsage > 0.8) {
        console.warn(`âš ï¸ High memory usage: ${(healthMetrics.memoryUsage * 100).toFixed(2)}%`);
      }

      if (healthMetrics.connections > 800) {
        console.warn(`âš ï¸ High connection count: ${healthMetrics.connections}`);
      }

      // ë©”íŠ¸ë¦­ì„ Redisì— ì €ì¥ (ëª¨ë‹ˆí„°ë§ìš©)
      this.saveHealthMetrics(healthMetrics);
    }, 10000); // 10ì´ˆë§ˆë‹¤

    return healthMetrics;
  }

  // í—¬ìŠ¤ ë©”íŠ¸ë¦­ ì €ì¥
  async saveHealthMetrics(metrics) {
    try {
      const redisClient = require('../utils/redisClient');
      await redisClient.setEx(
        `server:health:${process.pid}`,
        30,
        JSON.stringify({
          ...metrics,
          pid: process.pid,
          timestamp: new Date()
        })
      );
    } catch (error) {
      console.error('Failed to save health metrics:', error);
    }
  }

  // ì •ë¦¬ ì‘ì—…
  async cleanup() {
    if (this.redisClients) {
      await Promise.all([
        this.redisClients.pubClient.quit(),
        this.redisClients.subClient.quit()
      ]);
    }
  }
}

module.exports = new SocketClusterService(); 